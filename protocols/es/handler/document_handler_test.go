// Copyright (c) 2024 TigerDB Authors
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
// 		http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package handler

import (
	"bytes"
	"encoding/json"
	"fmt"
	"net/http"
	"net/http/httptest"
	"os"
	"strings"
	"testing"
	"time"

	"github.com/gorilla/mux"
	"github.com/lscgzwd/tiggerdb/directory"
	"github.com/lscgzwd/tiggerdb/metadata"
	esIndex "github.com/lscgzwd/tiggerdb/protocols/es/index"
)

func TestBulkAndCountIntegration(t *testing.T) {
	// åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºæµ‹è¯•
	tempDir, err := os.MkdirTemp("", "tigerdb_test_*")
	if err != nil {
		t.Fatalf("Failed to create temp dir: %v", err)
	}
	defer os.RemoveAll(tempDir)

	// è®¾ç½®ç›®å½•é…ç½®
	config := &directory.DirectoryConfig{
		BaseDir:           tempDir,
		DirPerm:           0755,
		MaxIndices:        10,
		MaxTables:         100,
		MaxAge:            time.Hour,
		EnableAutoCleanup: false,
	}

	// åˆ›å»ºç›®å½•ç®¡ç†å™¨
	dirMgr, err := directory.NewDirectoryManager(config)
	if err != nil {
		t.Fatalf("Failed to create directory manager: %v", err)
	}

	// åˆ›å»ºå…ƒæ•°æ®å­˜å‚¨é…ç½®
	metaConfig := &metadata.MetadataStoreConfig{
		StorageType: "file",
		FilePath:    tempDir,
		EnableCache: true,
	}
	metaStore, err := metadata.NewFileMetadataStore(metaConfig)
	if err != nil {
		t.Fatalf("Failed to create metadata store: %v", err)
	}

	// åˆ›å»ºç´¢å¼•ç®¡ç†å™¨
	indexMgr := esIndex.NewIndexManager(dirMgr, metaStore)

	// åˆ›å»ºæ–‡æ¡£å¤„ç†å™¨
	docHandler := NewDocumentHandler(indexMgr, dirMgr, metaStore)

	// åˆ›å»ºæµ‹è¯•ç´¢å¼•
	indexName := "test_bulk_count"

	// åˆ›å»ºç´¢å¼•å¤„ç†å™¨
	indexHandler := NewIndexHandler(dirMgr, metaStore)
	indexHandler.SetIndexManager(indexMgr)

	// åˆ›å»ºç´¢å¼•
	req := httptest.NewRequest("PUT", "/"+indexName, nil)
	req = mux.SetURLVars(req, map[string]string{"index": indexName})
	w := httptest.NewRecorder()
	indexHandler.CreateIndex(w, req)
	if w.Code != http.StatusOK {
		t.Fatalf("Failed to create index: %s", w.Body.String())
	}

	// å‡†å¤‡bulkæ•°æ®
	bulkData := `{"index":{"_index":"` + indexName + `","_id":"doc1"}}
{"name":"test document 1","value":1,"nested":{"field":"value1"}}
{"index":{"_index":"` + indexName + `","_id":"doc2"}}
{"name":"test document 2","value":2,"nested":{"field":"value2"}}
{"index":{"_index":"` + indexName + `","_id":"doc3"}}
{"name":"test document 3","value":3}`

	// æ‰§è¡Œbulkæ“ä½œ
	bulkReq := httptest.NewRequest("POST", "/_bulk", strings.NewReader(bulkData))
	bulkReq.Header.Set("Content-Type", "application/x-ndjson")
	bulkW := httptest.NewRecorder()
	docHandler.Bulk(bulkW, bulkReq)

	if bulkW.Code != http.StatusOK {
		t.Fatalf("Bulk operation failed: %s", bulkW.Body.String())
	}

	// éªŒè¯bulkå“åº”
	var bulkResp BulkResponse
	if err := json.Unmarshal(bulkW.Body.Bytes(), &bulkResp); err != nil {
		t.Fatalf("Failed to parse bulk response: %v", err)
	}

	if len(bulkResp.Items) != 3 {
		t.Fatalf("Expected 3 bulk items, got %d", len(bulkResp.Items))
	}

	// ç­‰å¾…ç´¢å¼•åˆ·æ–°
	time.Sleep(100 * time.Millisecond)

	// æ‰§è¡ŒcountæŸ¥è¯¢
	countData := `{"query":{"match_all":{}}}`
	countReq := httptest.NewRequest("POST", "/"+indexName+"/_count", strings.NewReader(countData))
	countReq.Header.Set("Content-Type", "application/json")
	countReq = mux.SetURLVars(countReq, map[string]string{"index": indexName})
	countW := httptest.NewRecorder()
	docHandler.CountDocuments(countW, countReq)

	if countW.Code != http.StatusOK {
		t.Fatalf("Count operation failed: %s", countW.Body.String())
	}

	// éªŒè¯countå“åº”
	var countResp map[string]interface{}
	if err := json.Unmarshal(countW.Body.Bytes(), &countResp); err != nil {
		t.Fatalf("Failed to parse count response: %v", err)
	}

	count, ok := countResp["count"].(float64)
	if !ok {
		t.Fatalf("Count response missing count field: %v", countResp)
	}

	if int(count) != 3 {
		t.Fatalf("Expected count 3, got %d", int(count))
	}

	t.Logf("Bulk and count integration test passed: indexed 3 documents, counted %d documents", int(count))
}

// TestProductionLikeBulkAndCountIntegration æµ‹è¯•ç±»ä¼¼ç”Ÿäº§ç¯å¢ƒçš„bulkå’Œcounté›†æˆ
func TestProductionLikeBulkAndCountIntegration(t *testing.T) {
	// åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºæµ‹è¯•
	tempDir, err := os.MkdirTemp("", "tigerdb_prod_like_test_*")
	if err != nil {
		t.Fatalf("Failed to create temp dir: %v", err)
	}
	defer os.RemoveAll(tempDir)

	// è®¾ç½®ç›®å½•é…ç½® - æ¨¡æ‹Ÿç”Ÿäº§ç¯å¢ƒé…ç½®
	config := &directory.DirectoryConfig{
		BaseDir:           tempDir,
		DirPerm:           0755,
		MaxIndices:        100,
		MaxTables:         1000,
		MaxAge:            24 * time.Hour,
		EnableAutoCleanup: true,
	}

	// åˆ›å»ºç›®å½•ç®¡ç†å™¨
	dirMgr, err := directory.NewDirectoryManager(config)
	if err != nil {
		t.Fatalf("Failed to create directory manager: %v", err)
	}

	// åˆ›å»ºå…ƒæ•°æ®å­˜å‚¨ - ä½¿ç”¨æ–‡ä»¶å­˜å‚¨æ¨¡æ‹Ÿç”Ÿäº§ç¯å¢ƒ
	metaConfig := &metadata.MetadataStoreConfig{
		StorageType:      "file",
		FilePath:         tempDir,
		EnableCache:      true,
		EnableVersioning: true,
	}
	metaStore, err := metadata.NewFileMetadataStore(metaConfig)
	if err != nil {
		t.Fatalf("Failed to create metadata store: %v", err)
	}

	// åˆ›å»ºç´¢å¼•ç®¡ç†å™¨
	indexMgr := esIndex.NewIndexManager(dirMgr, metaStore)

	// åˆ›å»ºæ–‡æ¡£å¤„ç†å™¨
	docHandler := NewDocumentHandler(indexMgr, dirMgr, metaStore)

	// åˆ›å»ºæµ‹è¯•ç´¢å¼• - ä½¿ç”¨ç±»ä¼¼ç”Ÿäº§ç¯å¢ƒçš„ç´¢å¼•å
	indexName := "foeye_task_assets"

	// åˆ›å»ºç´¢å¼•å¤„ç†å™¨
	indexHandler := NewIndexHandler(dirMgr, metaStore)
	indexHandler.SetIndexManager(indexMgr)

	// åˆ›å»ºç´¢å¼•
	req := httptest.NewRequest("PUT", "/"+indexName, nil)
	req = mux.SetURLVars(req, map[string]string{"index": indexName})
	w := httptest.NewRecorder()
	indexHandler.CreateIndex(w, req)
	if w.Code != http.StatusOK {
		t.Fatalf("Failed to create index: %s", w.Body.String())
	}

	// å‡†å¤‡bulkæ•°æ® - æ¨¡æ‹Ÿç”Ÿäº§ç¯å¢ƒçš„æ•°æ®ç»“æ„ï¼ˆåŒ…å«åµŒå¥—æ–‡æ¡£ï¼‰
	var bulkLines []string
	docCount := 100 // æ¨¡æ‹Ÿç”Ÿäº§ç¯å¢ƒçš„æ–‡æ¡£æ•°é‡

	for i := 1; i <= docCount; i++ {
		ip := fmt.Sprintf("192.168.1.%d", i%255+1)
		docID := fmt.Sprintf("asset_%d", i)

		// æ·»åŠ ç´¢å¼•å…ƒæ•°æ®
		bulkLines = append(bulkLines, fmt.Sprintf(`{"index":{"_index":"%s","_id":"%s"}}`, indexName, docID))

		// æ·»åŠ æ–‡æ¡£æ•°æ® - æ¨¡æ‹Ÿç”Ÿäº§ç¯å¢ƒçš„æ•°æ®ç»“æ„
		docData := fmt.Sprintf(`{
			"ip": "%s",
			"hostname": "host-%d.example.com",
			"ports": [
				{"port": 80, "service": "http", "status": "open"},
				{"port": 443, "service": "https", "status": "open"}
			],
			"vulnerabilities": [
				{"id": "CVE-2023-1234", "severity": "high", "cvss": 8.5},
				{"id": "CVE-2023-5678", "severity": "medium", "cvss": 5.0}
			],
			"tags": ["production", "web-server"],
			"last_scan": "2024-01-01T10:00:00Z",
			"status": "active"
		}`, ip, i)

		// å‹ç¼©JSONï¼ˆç§»é™¤æ¢è¡Œå’Œç©ºæ ¼ï¼‰
		docData = strings.ReplaceAll(docData, "\n", "")
		docData = strings.ReplaceAll(docData, "\t", "")
		docData = strings.ReplaceAll(docData, "  ", "")

		bulkLines = append(bulkLines, docData)
	}

	// åˆå¹¶æ‰€æœ‰bulkæ•°æ®
	bulkData := strings.Join(bulkLines, "\n")

	// æ‰§è¡Œbulkæ“ä½œ
	bulkReq := httptest.NewRequest("POST", "/_bulk?refresh=true", strings.NewReader(bulkData))
	bulkReq.Header.Set("Content-Type", "application/x-ndjson")
	bulkW := httptest.NewRecorder()
	docHandler.Bulk(bulkW, bulkReq)

	if bulkW.Code != http.StatusOK {
		t.Fatalf("Bulk operation failed: %s", bulkW.Body.String())
	}

	// éªŒè¯bulkå“åº”
	var bulkResp map[string]interface{}
	if err := json.Unmarshal(bulkW.Body.Bytes(), &bulkResp); err != nil {
		t.Fatalf("Failed to parse bulk response: %v", err)
	}

	// æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
	if errors, ok := bulkResp["errors"].(bool); ok && errors {
		t.Fatalf("Bulk operation had errors: %s", bulkW.Body.String())
	}

	// è®°å½•bulkæ“ä½œç»“æœ
	t.Logf("Bulk operation completed: inserted %d documents", docCount)

	// ç­‰å¾…ç´¢å¼•åˆ·æ–° - æ¨¡æ‹Ÿç”Ÿäº§ç¯å¢ƒ
	time.Sleep(1 * time.Second)

	// æµ‹è¯•1: åŸºæœ¬çš„countæŸ¥è¯¢ï¼ˆæ— æ¡ä»¶ï¼‰- è¿™æ˜¯ç”Ÿäº§ç¯å¢ƒä¸­å¤±è´¥çš„æŸ¥è¯¢
	t.Log("Testing basic count query (the failing one in production)")
	countReq := httptest.NewRequest("POST", "/"+indexName+"/_count", strings.NewReader("{}"))
	countReq.Header.Set("Content-Type", "application/json")
	countReq = mux.SetURLVars(countReq, map[string]string{"index": indexName})
	countW := httptest.NewRecorder()
	docHandler.CountDocuments(countW, countReq)

	if countW.Code != http.StatusOK {
		t.Fatalf("Count operation failed: %s", countW.Body.String())
	}

	// éªŒè¯countå“åº”
	var countResp map[string]interface{}
	if err := json.Unmarshal(countW.Body.Bytes(), &countResp); err != nil {
		t.Fatalf("Failed to parse count response: %v", err)
	}

	count, ok := countResp["count"].(float64)
	if !ok {
		t.Fatalf("Count response missing count field: %v", countResp)
	}

	if int(count) != docCount {
		t.Fatalf("CRITICAL BUG: Expected count %d, got %d. This is the production issue!", docCount, int(count))
	}

	t.Logf("âœ… Basic count test PASSED: counted %d documents", int(count))

	// æµ‹è¯•2: éªŒè¯ç´¢å¼•å®ä¾‹ä¸€è‡´æ€§ - å¤šæ¬¡æŸ¥è¯¢åº”è¯¥è¿”å›ç›¸åŒç»“æœ
	for i := 0; i < 3; i++ {
		countReq2 := httptest.NewRequest("POST", "/"+indexName+"/_count", strings.NewReader("{}"))
		countReq2.Header.Set("Content-Type", "application/json")
		countReq2 = mux.SetURLVars(countReq2, map[string]string{"index": indexName})
		countW2 := httptest.NewRecorder()
		docHandler.CountDocuments(countW2, countReq2)

		if countW2.Code != http.StatusOK {
			t.Fatalf("Count operation %d failed: %s", i+1, countW2.Body.String())
		}

		var countResp2 map[string]interface{}
		if err := json.Unmarshal(countW2.Body.Bytes(), &countResp2); err != nil {
			t.Fatalf("Failed to parse count response %d: %v", i+1, err)
		}

		count2, ok := countResp2["count"].(float64)
		if !ok {
			t.Fatalf("Count response %d missing count field: %v", i+1, countResp2)
		}

		if int(count2) != docCount {
			t.Fatalf("Index instance inconsistency: query %d expected %d, got %d", i+1, docCount, int(count2))
		}

		t.Logf("âœ… Count consistency check %d PASSED: %d documents", i+1, int(count2))
	}

	// æµ‹è¯•3: SearchæŸ¥è¯¢éªŒè¯ - ç¡®ä¿æ•°æ®å¯æœç´¢
	searchData := `{"query":{"match_all":{}},"size":5}`
	searchReq := httptest.NewRequest("POST", "/"+indexName+"/_search", strings.NewReader(searchData))
	searchReq.Header.Set("Content-Type", "application/json")
	searchReq = mux.SetURLVars(searchReq, map[string]string{"index": indexName})
	searchW := httptest.NewRecorder()
	docHandler.Search(searchW, searchReq)

	if searchW.Code != http.StatusOK {
		t.Fatalf("Search operation failed: %s", searchW.Body.String())
	}

	// éªŒè¯searchå“åº”
	var searchResp map[string]interface{}
	if err := json.Unmarshal(searchW.Body.Bytes(), &searchResp); err != nil {
		t.Fatalf("Failed to parse search response: %v", err)
	}

	hits, ok := searchResp["hits"].(map[string]interface{})
	if !ok {
		t.Fatalf("Search response missing hits field: %v", searchResp)
	}

	total, ok := hits["total"].(map[string]interface{})
	if !ok {
		t.Fatalf("Search response missing total field: %v", hits)
	}

	searchCount, ok := total["value"].(float64)
	if !ok {
		t.Fatalf("Search total missing value field: %v", total)
	}

	if int(searchCount) != docCount {
		t.Fatalf("Search count mismatch: expected %d, got %d. Response: %s", docCount, int(searchCount), searchW.Body.String())
	}

	t.Logf("âœ… Search test PASSED: found %d documents via search", int(searchCount))

	// æµ‹è¯•4: å¹¶å‘è®¿é—®æµ‹è¯• - æ¨¡æ‹Ÿç”Ÿäº§ç¯å¢ƒçš„å¹¶å‘æŸ¥è¯¢
	t.Log("Testing concurrent access (simulating production load)")
	done := make(chan bool, 10)
	errorCount := 0

	for i := 0; i < 10; i++ {
		go func(goroutineID int) {
			defer func() { done <- true }()

			// æ¯ä¸ªgoroutineæ‰§è¡Œå¤šæ¬¡countæŸ¥è¯¢
			for j := 0; j < 5; j++ {
				countReq := httptest.NewRequest("POST", "/"+indexName+"/_count", strings.NewReader("{}"))
				countReq.Header.Set("Content-Type", "application/json")
				countReq = mux.SetURLVars(countReq, map[string]string{"index": indexName})
				countW := httptest.NewRecorder()

				docHandler.CountDocuments(countW, countReq)

				if countW.Code != http.StatusOK {
					t.Errorf("Concurrent count operation failed in goroutine %d, attempt %d: %s", goroutineID, j, countW.Body.String())
					errorCount++
					return
				}

				var countResp map[string]interface{}
				if err := json.Unmarshal(countW.Body.Bytes(), &countResp); err != nil {
					t.Errorf("Failed to parse concurrent count response in goroutine %d, attempt %d: %v", goroutineID, j, err)
					errorCount++
					return
				}

				count, ok := countResp["count"].(float64)
				if !ok || int(count) != docCount {
					t.Errorf("Concurrent count inconsistency in goroutine %d, attempt %d: expected %d, got %v", goroutineID, j, docCount, countResp)
					errorCount++
					return
				}
			}
		}(i)
	}

	// ç­‰å¾…æ‰€æœ‰goroutineå®Œæˆ
	for i := 0; i < 10; i++ {
		<-done
	}

	if errorCount > 0 {
		t.Fatalf("Concurrent access test FAILED: %d errors occurred", errorCount)
	}

	t.Log("âœ… Concurrent access test PASSED: 10 goroutines x 5 queries each = 50 successful queries")

	// æµ‹è¯•5: éªŒè¯æ•°æ®å®Œæ•´æ€§ - éšæœºæŠ½æ ·æ£€æŸ¥æ–‡æ¡£å†…å®¹
	hitsArray, ok := hits["hits"].([]interface{})
	if !ok || len(hitsArray) == 0 {
		t.Fatalf("No hits returned for data validation")
	}

	// æ£€æŸ¥å‰3ä¸ªæ–‡æ¡£çš„æ•°æ®å®Œæ•´æ€§
	for i := 0; i < 3 && i < len(hitsArray); i++ {
		hit, ok := hitsArray[i].(map[string]interface{})
		if !ok {
			t.Fatalf("Invalid hit format at index %d", i)
		}

		source, ok := hit["_source"].(map[string]interface{})
		if !ok {
			t.Fatalf("Missing _source in hit at index %d", i)
		}

		// éªŒè¯å…³é”®å­—æ®µå­˜åœ¨
		if _, hasIP := source["ip"]; !hasIP {
			t.Fatalf("Document %d missing ip field", i)
		}

		if _, hasPorts := source["ports"]; !hasPorts {
			t.Fatalf("Document %d missing ports field", i)
		}

		if _, hasTags := source["tags"]; !hasTags {
			t.Fatalf("Document %d missing tags field", i)
		}

		t.Logf("âœ… Document %d data integrity check PASSED", i)
	}

	t.Logf("ğŸ‰ PRODUCTION-LIKE INTEGRATION TEST COMPLETELY PASSED:")
	t.Logf("   - Bulk indexed: %d documents", docCount)
	t.Logf("   - Count queries: consistent results")
	t.Logf("   - Search queries: working correctly")
	t.Logf("   - Concurrent access: no race conditions")
	t.Logf("   - Data integrity: all documents valid")
	t.Logf("   - Index consistency: stable across operations")
}

func TestDocumentHandler(t *testing.T) {
	// åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºæµ‹è¯•
	tempDir, err := os.MkdirTemp("", "tigerdb_test_*")
	if err != nil {
		t.Fatalf("Failed to create temp dir: %v", err)
	}
	defer os.RemoveAll(tempDir)

	// è®¾ç½®ç›®å½•é…ç½®
	config := &directory.DirectoryConfig{
		BaseDir:           tempDir,
		DirPerm:           0755,
		MaxIndices:        10,
		MaxTables:         100,
		MaxAge:            time.Hour,
		EnableAutoCleanup: false,
	}

	// åˆ›å»ºç›®å½•ç®¡ç†å™¨
	dirMgr, err := directory.NewDirectoryManager(config)
	if err != nil {
		t.Fatalf("Failed to create directory manager: %v", err)
	}

	// åˆ›å»ºå…ƒæ•°æ®å­˜å‚¨é…ç½®
	metaConfig := &metadata.MetadataStoreConfig{
		StorageType: "file",
		FilePath:    tempDir,
		EnableCache: true,
	}
	metaStore, err := metadata.NewFileMetadataStore(metaConfig)
	if err != nil {
		t.Fatalf("Failed to create metadata store: %v", err)
	}

	// åˆ›å»ºç´¢å¼•ç®¡ç†å™¨
	indexMgr := esIndex.NewIndexManager(dirMgr, metaStore)

	// åˆ›å»ºæ–‡æ¡£å¤„ç†å™¨
	docHandler := NewDocumentHandler(indexMgr, dirMgr, metaStore)

	// åˆ›å»ºæµ‹è¯•ç´¢å¼•
	indexName := "test_index"

	// åˆ›å»ºç´¢å¼•å¤„ç†å™¨
	indexHandler := NewIndexHandler(dirMgr, metaStore)
	indexHandler.SetIndexManager(indexMgr)

	// åˆ›å»ºç´¢å¼•
	req := httptest.NewRequest("PUT", "/"+indexName, nil)
	req = mux.SetURLVars(req, map[string]string{"index": indexName})
	w := httptest.NewRecorder()
	indexHandler.CreateIndex(w, req)
	if w.Code != http.StatusOK {
		t.Fatalf("Failed to create index: %s", w.Body.String())
	}

	// æµ‹è¯•åˆ›å»ºæ–‡æ¡£
	docData := map[string]interface{}{
		"name":  "test document",
		"value": 42,
		"nested": map[string]interface{}{
			"field": "nested value",
		},
	}

	docJSON, _ := json.Marshal(docData)
	createReq := httptest.NewRequest("POST", "/"+indexName+"/_doc/doc1", bytes.NewReader(docJSON))
	createReq.Header.Set("Content-Type", "application/json")
	createReq = mux.SetURLVars(createReq, map[string]string{"index": indexName})
	createW := httptest.NewRecorder()
	docHandler.CreateDocument(createW, createReq)

	if createW.Code != http.StatusCreated {
		t.Logf("Create document failed: %s", createW.Body.String())
	} else {
		t.Log("Document creation test passed")
	}

	t.Log("Document handler basic test completed")
}
